---
title: "Racial Differences in Earnings in the United States"
author: "Tom Vogl"
output: pdf_document
---

This coding example estimates racial differences in earnings using data from
the National Longitudinal Survey of Youth '79. Let's load the packages we
need as well as the data.

```{r setup, include=FALSE}
knitr::opts_chunk$set(results = 'hide', fig.show = 'hide')
```

```{r message=FALSE, warning=FALSE}
rm(list=ls())
library(tidyverse)
library(fixest)

# load nlsy79.Rdata
load(url("https://github.com/tomvogl/econ121/raw/main/data/nlsy79.rds"))
```

To get started, Let's look at the structure of the dataset.

```{r}
glimpse(nlsy79)
```

What are the mean and SD of labor income?

```{r}
mean(nlsy79$laborinc18,na.rm=TRUE)
sd(nlsy79$laborinc18,na.rm=TRUE)
```

How about percentiles?

```{r}
summary(nlsy79$laborinc18)
```

We can see more detail when we plot histograms by race.

```{r}
ggplot(nlsy79, aes(x = laborinc18)) +
  geom_histogram() +
  facet_wrap(~black, ncol=1) # separate graphs by race, stacked into one column
```

We will estimate differences in mean income between blacks and non-blacks. 
Let's look at means by race.

```{r}
nlsy79 %>% 
  drop_na(laborinc18) %>% # removes NA values so we don't need to use na.rm
  group_by(black) %>% 
  summarize(mean=mean(laborinc18),
            sd=sd(laborinc18),
            n=n())
```

These results give us all the information we need to test for differences by race.
The difference is:
```{r}
50798-31505
```
And the t-statistic is
```{r}
(50798-31505)/sqrt(70856^2/4558 + 46907^2/2013)
```
which is well above 1.96, so statistically significant by the usual standards.

An alternative way to run this test is the t-test with unequal variances:
```{r}
t.test(laborinc18 ~ black, data = nlsy79)
```
Equivalently, we can run a regression with heteroskedasticity-robust SEs, 
using feols() from fixest package
```{r}
feols(laborinc18 ~ black, data = nlsy79, vcov = 'hetero')
```
Note that lm() is the base-R way to estimate a regression, but it doesn't 
directly allow for robust standard errors, and you need to use summary()
to even see classical standard errors. feols() from fixest is more convenient.
```{r}
model1 <- lm(laborinc18 ~ black, data = nlsy79)
model1
summary(model1)
```

It is actually uncommon to test for average differences in the level 
(rather than log) of earnings, including zeros from the non-employed. 
It would be much more typical to restrict to employed individuals. So 
let's restrict to people restrict to people who worked for pay for at least 
1000 hours: equivalent to a part-time job of 20 hours per week for 50 weeks.
```{r}
summary(nlsy79$hours18)

nlsy79_workers <- 
  nlsy79 %>% 
  filter(hours18>=1000 & laborinc18>0)

summary(nlsy79_workers$hours18)
```

Means by race in the workers sample:
```{r}
nlsy79_workers %>% 
  drop_na(laborinc18) %>%
  group_by(black) %>% 
  summarize(mean=mean(laborinc18),
            sd=sd(laborinc18),
            n=n())
```
Still a $19k difference.

Now let's look at log earnings.
```{r}
nlsy79_workers <- 
  nlsy79_workers %>% 
  mutate(loginc18 = log(laborinc18))

# the format() function is just to report more decimal places
nlsy79_workers %>% 
  drop_na(loginc18) %>%
  group_by(black) %>% 
  summarize(mean=format(mean(loginc18, na.rm = TRUE)),
            sd=sd(loginc18, na.rm = TRUE),
            n=n())
```

The difference is:
```{r}
10.851-10.616
```

This difference in logs can by roughly interpreted as a 23.5% gap in earnings, 
although this interpretation relies on calculus [dln(y)/dx]. Since we are doing a 
comparison by a discrete variable, we can think of 23.5% as an approximation .

The t-statistic is now:
```{r}
(10.851-10.616)/sqrt(.867^2/3015 + .849^2/1078)
```
Again well above 1.96, so statistically significant by the usual standards.

As an alterantive way to do the same thing, we can run a t-test with unequal variances:
```{r}
t.test(loginc18 ~ black, data = nlsy79_workers)
```

Or run a regression with heteroskedasticity-robust standard errors:
```{r}
feols(loginc18 ~ black, data = nlsy79_workers, vcov = 'hetero')
```
Same results. That is to say, a regression on a "dummy variable"
for black leads to the same results as a difference of means
Note that the t-statistic is very slightly different from what
we computed "by hand." That's likely due to rounding errors.

